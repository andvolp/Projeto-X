{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1ttYx_BubTg7gailiVB-DwsSf3QIx-cBk","timestamp":1690950255869},{"file_id":"1pI_DDTNmKsMfrHuxk-Ki53n9Eu1trVdw","timestamp":1690700941833},{"file_id":"14I8sIz1o_lt_54aYMgtinN584MZ1YMS5","timestamp":1690168233301},{"file_id":"12_BRZr-81GUBTOfoWh9UY5jxGuuRfU67","timestamp":1689647348513},{"file_id":"1gTnY5m8Oqcc22gvv7Q-Vu3Furn28v7o_","timestamp":1689462466876},{"file_id":"1eV8z9hqB1tLVW--hghWBjVoAaRf7HAEM","timestamp":1689399741826}],"gpuType":"T4","authorship_tag":"ABX9TyPrHvUyd9N6WpTRpZcb+/BE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"_xfwnVnfrWdK"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import tensorflow\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, BatchNormalization\n","import tensorflow as tf\n","import io\n","from tensorflow.keras.utils import to_categorical\n","from google.colab import files"]},{"cell_type":"code","source":["\n","df = pd.read_csv('https://raw.githubusercontent.com/andvolp/Projeto-X/main/Projeto%201/winequality-white.csv', encoding='utf-8', sep=';')\n","\n","dfs = np.array(df)\n","\n","for i in range(len(dfs)):\n","  if dfs[i,11] > 5:\n","    dfs[i,11] = 1\n","  else:\n","    dfs[i,11] = 0\n","\n","# utilizarei o keras\n","\n","X = dfs[:,:-1]\n","y = dfs[:,11]\n","\n","scaler =StandardScaler()\n","X = scaler.fit_transform(X)\n","\n","X_train, X_test, y_train, y_test = train_test_split(X , y, test_size=0.2, random_state=3)\n","\n","\n","model = Sequential()\n","\n","model.add(tf.keras.Input(shape=(11,)))\n","\n","#Fully layer 1\n","model.add(tf.keras.layers.Flatten())\n","model.add(tf.keras.layers.Dense(1024))\n","#model.add(BatchNormalization())\n","model.add(tf.keras.layers.Activation('relu'))\n","model.add(tf.keras.layers.Dropout(0.1))\n","\n","#Fully layer 2\n","model.add(tf.keras.layers.Flatten())\n","model.add(tf.keras.layers.Dense(1024))\n","#model.add(BatchNormalization())\n","model.add(tf.keras.layers.Activation('relu'))\n","model.add(tf.keras.layers.Dropout(0.1))\n","\n","#Fully layer 3\n","model.add(tf.keras.layers.Flatten())\n","model.add(tf.keras.layers.Dense(1024))\n","#model.add(BatchNormalization())\n","model.add(tf.keras.layers.Activation('relu'))\n","model.add(tf.keras.layers.Dropout(0.1))\n","\n","#Fully layer 4\n","model.add(tf.keras.layers.Flatten())\n","model.add(tf.keras.layers.Dense(1024))\n","#model.add(BatchNormalization())\n","model.add(tf.keras.layers.Activation('sigmoid'))\n","model.add(tf.keras.layers.Dropout(0.1))\n","\n","#Output\n","model.add(Dense(1))\n","model.add(tf.keras.layers.Activation('tanh'))\n","\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","historico = model.fit(X_train, y_train, epochs=300, batch_size=124, verbose=1)\n","\n","loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n","\n","log_stream = io.StringIO()\n","log_stream.write(f\"Loss: {loss}, Accuracy: {accuracy}\\n\")\n","log_stream.write(str(historico.history))\n","\n"," #Salvar o arquivo de log em disco\n","with open('historico.log', 'w') as f:\n","    f.write(log_stream.getvalue())\n","\n","#files.download('/content/history.log')\n","\n","print('Acuracia:', accuracy)\n","print('loss', loss)"],"metadata":{"id":"aiMSinsFsCeh","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5b32570b-533a-48bc-dbac-2b1dde30dbda","executionInfo":{"status":"ok","timestamp":1690870118602,"user_tz":180,"elapsed":83643,"user":{"displayName":"Andr√© Felipe Shimizu Volpato","userId":"16593900034578429908"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/300\n","32/32 [==============================] - 2s 5ms/step - loss: 0.7326 - accuracy: 0.6853\n","Epoch 2/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.6522 - accuracy: 0.7185\n","Epoch 3/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.6316 - accuracy: 0.7325\n","Epoch 4/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.6978 - accuracy: 0.7057\n","Epoch 5/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.5423 - accuracy: 0.7305\n","Epoch 6/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.6643 - accuracy: 0.7264\n","Epoch 7/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.7195 - accuracy: 0.7404\n","Epoch 8/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.6034 - accuracy: 0.7379\n","Epoch 9/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.6150 - accuracy: 0.7192\n","Epoch 10/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.5843 - accuracy: 0.7466\n","Epoch 11/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.5712 - accuracy: 0.7555\n","Epoch 12/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.5133 - accuracy: 0.7330\n","Epoch 13/300\n","32/32 [==============================] - 0s 5ms/step - loss: 1.1752 - accuracy: 0.6998\n","Epoch 14/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.7627 - accuracy: 0.7203\n","Epoch 15/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.8591 - accuracy: 0.7215\n","Epoch 16/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.7080 - accuracy: 0.7366\n","Epoch 17/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.9262 - accuracy: 0.7238\n","Epoch 18/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.8416 - accuracy: 0.6950\n","Epoch 19/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.6689 - accuracy: 0.7200\n","Epoch 20/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.5166 - accuracy: 0.7369\n","Epoch 21/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.5123 - accuracy: 0.7496\n","Epoch 22/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.5374 - accuracy: 0.7647\n","Epoch 23/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.4955 - accuracy: 0.7810\n","Epoch 24/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.5636 - accuracy: 0.7672\n","Epoch 25/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.6511 - accuracy: 0.7192\n","Epoch 26/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.7218 - accuracy: 0.7192\n","Epoch 27/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.7098 - accuracy: 0.7534\n","Epoch 28/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.5858 - accuracy: 0.7524\n","Epoch 29/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.5022 - accuracy: 0.7820\n","Epoch 30/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.5588 - accuracy: 0.7749\n","Epoch 31/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.5690 - accuracy: 0.7649\n","Epoch 32/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.5931 - accuracy: 0.7552\n","Epoch 33/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.4517 - accuracy: 0.8017\n","Epoch 34/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.4971 - accuracy: 0.7757\n","Epoch 35/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.4813 - accuracy: 0.8203\n","Epoch 36/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.5020 - accuracy: 0.7716\n","Epoch 37/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.4520 - accuracy: 0.8356\n","Epoch 38/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.4209 - accuracy: 0.8382\n","Epoch 39/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.4228 - accuracy: 0.8509\n","Epoch 40/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.4234 - accuracy: 0.8481\n","Epoch 41/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.5383 - accuracy: 0.7846\n","Epoch 42/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.4851 - accuracy: 0.8063\n","Epoch 43/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.4331 - accuracy: 0.8499\n","Epoch 44/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.4428 - accuracy: 0.8336\n","Epoch 45/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.3669 - accuracy: 0.8517\n","Epoch 46/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.4157 - accuracy: 0.8629\n","Epoch 47/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.3716 - accuracy: 0.8800\n","Epoch 48/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.3843 - accuracy: 0.8680\n","Epoch 49/300\n","32/32 [==============================] - 0s 8ms/step - loss: 0.4252 - accuracy: 0.8583\n","Epoch 50/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.3330 - accuracy: 0.8650\n","Epoch 51/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.3299 - accuracy: 0.8683\n","Epoch 52/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.3276 - accuracy: 0.8831\n","Epoch 53/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.3690 - accuracy: 0.8698\n","Epoch 54/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.5045 - accuracy: 0.7815\n","Epoch 55/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.6574 - accuracy: 0.7560\n","Epoch 56/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.4259 - accuracy: 0.8290\n","Epoch 57/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.3892 - accuracy: 0.8670\n","Epoch 58/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.5468 - accuracy: 0.8530\n","Epoch 59/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.3862 - accuracy: 0.8596\n","Epoch 60/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.3669 - accuracy: 0.8775\n","Epoch 61/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.6076 - accuracy: 0.8165\n","Epoch 62/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.8258 - accuracy: 0.8157\n","Epoch 63/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.6601 - accuracy: 0.8129\n","Epoch 64/300\n","32/32 [==============================] - 0s 5ms/step - loss: 1.7351 - accuracy: 0.7175\n","Epoch 65/300\n","32/32 [==============================] - 0s 4ms/step - loss: 1.7450 - accuracy: 0.7445\n","Epoch 66/300\n","32/32 [==============================] - 0s 4ms/step - loss: 2.7939 - accuracy: 0.6797\n","Epoch 67/300\n","32/32 [==============================] - 0s 5ms/step - loss: 1.4548 - accuracy: 0.6866\n","Epoch 68/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.5158 - accuracy: 0.7384\n","Epoch 69/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.4773 - accuracy: 0.7596\n","Epoch 70/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.4615 - accuracy: 0.7848\n","Epoch 71/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.4325 - accuracy: 0.7889\n","Epoch 72/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.4265 - accuracy: 0.8058\n","Epoch 73/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.4023 - accuracy: 0.8157\n","Epoch 74/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.3964 - accuracy: 0.8193\n","Epoch 75/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.3805 - accuracy: 0.8203\n","Epoch 76/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.3898 - accuracy: 0.8387\n","Epoch 77/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.3657 - accuracy: 0.8474\n","Epoch 78/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.3508 - accuracy: 0.8548\n","Epoch 79/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.3528 - accuracy: 0.8571\n","Epoch 80/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.3187 - accuracy: 0.8645\n","Epoch 81/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.3252 - accuracy: 0.8686\n","Epoch 82/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.3093 - accuracy: 0.8757\n","Epoch 83/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.3101 - accuracy: 0.8770\n","Epoch 84/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.2835 - accuracy: 0.8823\n","Epoch 85/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.2547 - accuracy: 0.8941\n","Epoch 86/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.3026 - accuracy: 0.8846\n","Epoch 87/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.5583 - accuracy: 0.7453\n","Epoch 88/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.4390 - accuracy: 0.7460\n","Epoch 89/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.3071 - accuracy: 0.8660\n","Epoch 90/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.2807 - accuracy: 0.8885\n","Epoch 91/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.2819 - accuracy: 0.8811\n","Epoch 92/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.2660 - accuracy: 0.8943\n","Epoch 93/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.2590 - accuracy: 0.9051\n","Epoch 94/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.3006 - accuracy: 0.8668\n","Epoch 95/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.2876 - accuracy: 0.8770\n","Epoch 96/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.2500 - accuracy: 0.9048\n","Epoch 97/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.3402 - accuracy: 0.8538\n","Epoch 98/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.8152\n","Epoch 99/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.3202 - accuracy: 0.8701\n","Epoch 100/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.2638 - accuracy: 0.8946\n","Epoch 101/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.2354 - accuracy: 0.9084\n","Epoch 102/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.6428 - accuracy: 0.7348\n","Epoch 103/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.4101 - accuracy: 0.7869\n","Epoch 104/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.3027 - accuracy: 0.8624\n","Epoch 105/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.2694 - accuracy: 0.8859\n","Epoch 106/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.2488 - accuracy: 0.8974\n","Epoch 107/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.2714 - accuracy: 0.8925\n","Epoch 108/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.2564 - accuracy: 0.8959\n","Epoch 109/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.2457 - accuracy: 0.9056\n","Epoch 110/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.4728 - accuracy: 0.8185\n","Epoch 111/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.5360 - accuracy: 0.6975\n","Epoch 112/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.3565 - accuracy: 0.8259\n","Epoch 113/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.2726 - accuracy: 0.8760\n","Epoch 114/300\n","32/32 [==============================] - 0s 8ms/step - loss: 0.2697 - accuracy: 0.8971\n","Epoch 115/300\n","32/32 [==============================] - 0s 7ms/step - loss: 0.2384 - accuracy: 0.9058\n","Epoch 116/300\n","32/32 [==============================] - 0s 7ms/step - loss: 0.2147 - accuracy: 0.9158\n","Epoch 117/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.5413 - accuracy: 0.7152\n","Epoch 118/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.3971 - accuracy: 0.7616\n","Epoch 119/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.3127 - accuracy: 0.8612\n","Epoch 120/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.2659 - accuracy: 0.8925\n","Epoch 121/300\n","32/32 [==============================] - 0s 7ms/step - loss: 0.2169 - accuracy: 0.9119\n","Epoch 122/300\n","32/32 [==============================] - 0s 7ms/step - loss: 0.2276 - accuracy: 0.9199\n","Epoch 123/300\n","32/32 [==============================] - 0s 7ms/step - loss: 0.2159 - accuracy: 0.9158\n","Epoch 124/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1984 - accuracy: 0.9288\n","Epoch 125/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1748 - accuracy: 0.9359\n","Epoch 126/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1983 - accuracy: 0.9303\n","Epoch 127/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1899 - accuracy: 0.9326\n","Epoch 128/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1787 - accuracy: 0.9367\n","Epoch 129/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1750 - accuracy: 0.9370\n","Epoch 130/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1718 - accuracy: 0.9357\n","Epoch 131/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1683 - accuracy: 0.9410\n","Epoch 132/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1572 - accuracy: 0.9492\n","Epoch 133/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1549 - accuracy: 0.9418\n","Epoch 134/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1623 - accuracy: 0.9433\n","Epoch 135/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1887 - accuracy: 0.9232\n","Epoch 136/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1728 - accuracy: 0.9329\n","Epoch 137/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1908 - accuracy: 0.9260\n","Epoch 138/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.2490 - accuracy: 0.8933\n","Epoch 139/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1710 - accuracy: 0.9387\n","Epoch 140/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1466 - accuracy: 0.9479\n","Epoch 141/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1295 - accuracy: 0.9523\n","Epoch 142/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1165 - accuracy: 0.9535\n","Epoch 143/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.1236 - accuracy: 0.9479\n","Epoch 144/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1493 - accuracy: 0.9482\n","Epoch 145/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1013 - accuracy: 0.9594\n","Epoch 146/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1209 - accuracy: 0.9553\n","Epoch 147/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.2241 - accuracy: 0.9367\n","Epoch 148/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1952 - accuracy: 0.9290\n","Epoch 149/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1469 - accuracy: 0.9474\n","Epoch 150/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1515 - accuracy: 0.9507\n","Epoch 151/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1160 - accuracy: 0.9587\n","Epoch 152/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1218 - accuracy: 0.9622\n","Epoch 153/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1615 - accuracy: 0.9431\n","Epoch 154/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1090 - accuracy: 0.9640\n","Epoch 155/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1169 - accuracy: 0.9653\n","Epoch 156/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1077 - accuracy: 0.9607\n","Epoch 157/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0929 - accuracy: 0.9630\n","Epoch 158/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1083 - accuracy: 0.9607\n","Epoch 159/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0833 - accuracy: 0.9666\n","Epoch 160/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1039 - accuracy: 0.9655\n","Epoch 161/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1022 - accuracy: 0.9645\n","Epoch 162/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0928 - accuracy: 0.9686\n","Epoch 163/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0813 - accuracy: 0.9729\n","Epoch 164/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0997 - accuracy: 0.9689\n","Epoch 165/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0815 - accuracy: 0.9699\n","Epoch 166/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0736 - accuracy: 0.9732\n","Epoch 167/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1781 - accuracy: 0.9479\n","Epoch 168/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.2040 - accuracy: 0.9423\n","Epoch 169/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1711 - accuracy: 0.9354\n","Epoch 170/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1705 - accuracy: 0.9367\n","Epoch 171/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1254 - accuracy: 0.9571\n","Epoch 172/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1278 - accuracy: 0.9589\n","Epoch 173/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1196 - accuracy: 0.9648\n","Epoch 174/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1123 - accuracy: 0.9609\n","Epoch 175/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0906 - accuracy: 0.9650\n","Epoch 176/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0847 - accuracy: 0.9689\n","Epoch 177/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0927 - accuracy: 0.9706\n","Epoch 178/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0877 - accuracy: 0.9684\n","Epoch 179/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0846 - accuracy: 0.9701\n","Epoch 180/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0848 - accuracy: 0.9706\n","Epoch 181/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0902 - accuracy: 0.9696\n","Epoch 182/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0900 - accuracy: 0.9729\n","Epoch 183/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0954 - accuracy: 0.9704\n","Epoch 184/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0912 - accuracy: 0.9678\n","Epoch 185/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1458 - accuracy: 0.9569\n","Epoch 186/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1133 - accuracy: 0.9609\n","Epoch 187/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0802 - accuracy: 0.9745\n","Epoch 188/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0779 - accuracy: 0.9747\n","Epoch 189/300\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0706 - accuracy: 0.9758\n","Epoch 190/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0969 - accuracy: 0.9699\n","Epoch 191/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1335 - accuracy: 0.9576\n","Epoch 192/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0894 - accuracy: 0.9727\n","Epoch 193/300\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0844 - accuracy: 0.9694\n","Epoch 194/300\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0665 - accuracy: 0.9712\n","Epoch 195/300\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0516 - accuracy: 0.9803\n","Epoch 196/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0680 - accuracy: 0.9770\n","Epoch 197/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0859 - accuracy: 0.9755\n","Epoch 198/300\n","32/32 [==============================] - 0s 7ms/step - loss: 0.2258 - accuracy: 0.9290\n","Epoch 199/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1289 - accuracy: 0.9495\n","Epoch 200/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0925 - accuracy: 0.9691\n","Epoch 201/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1804 - accuracy: 0.9349\n","Epoch 202/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1026 - accuracy: 0.9592\n","Epoch 203/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0826 - accuracy: 0.9650\n","Epoch 204/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0906 - accuracy: 0.9671\n","Epoch 205/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0996 - accuracy: 0.9645\n","Epoch 206/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0726 - accuracy: 0.9699\n","Epoch 207/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0660 - accuracy: 0.9737\n","Epoch 208/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0648 - accuracy: 0.9781\n","Epoch 209/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0807 - accuracy: 0.9752\n","Epoch 210/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0769 - accuracy: 0.9770\n","Epoch 211/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0422 - accuracy: 0.9829\n","Epoch 212/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0628 - accuracy: 0.9806\n","Epoch 213/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0784 - accuracy: 0.9724\n","Epoch 214/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0459 - accuracy: 0.9806\n","Epoch 215/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0701 - accuracy: 0.9773\n","Epoch 216/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0694 - accuracy: 0.9793\n","Epoch 217/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0508 - accuracy: 0.9837\n","Epoch 218/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0502 - accuracy: 0.9796\n","Epoch 219/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0785 - accuracy: 0.9717\n","Epoch 220/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0961 - accuracy: 0.9653\n","Epoch 221/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0628 - accuracy: 0.9786\n","Epoch 222/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0492 - accuracy: 0.9826\n","Epoch 223/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0562 - accuracy: 0.9811\n","Epoch 224/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0496 - accuracy: 0.9826\n","Epoch 225/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0523 - accuracy: 0.9793\n","Epoch 226/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0972 - accuracy: 0.9668\n","Epoch 227/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.2369 - accuracy: 0.9245\n","Epoch 228/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1257 - accuracy: 0.9525\n","Epoch 229/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0947 - accuracy: 0.9668\n","Epoch 230/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0860 - accuracy: 0.9745\n","Epoch 231/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0562 - accuracy: 0.9791\n","Epoch 232/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0750 - accuracy: 0.9778\n","Epoch 233/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1041 - accuracy: 0.9722\n","Epoch 234/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0619 - accuracy: 0.9737\n","Epoch 235/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0558 - accuracy: 0.9816\n","Epoch 236/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0519 - accuracy: 0.9783\n","Epoch 237/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0662 - accuracy: 0.9816\n","Epoch 238/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0687 - accuracy: 0.9806\n","Epoch 239/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1158 - accuracy: 0.9645\n","Epoch 240/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1149 - accuracy: 0.9625\n","Epoch 241/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0892 - accuracy: 0.9694\n","Epoch 242/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0864 - accuracy: 0.9694\n","Epoch 243/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0816 - accuracy: 0.9773\n","Epoch 244/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0563 - accuracy: 0.9809\n","Epoch 245/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0684 - accuracy: 0.9796\n","Epoch 246/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0992 - accuracy: 0.9781\n","Epoch 247/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0551 - accuracy: 0.9842\n","Epoch 248/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0376 - accuracy: 0.9839\n","Epoch 249/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0469 - accuracy: 0.9857\n","Epoch 250/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0517 - accuracy: 0.9839\n","Epoch 251/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0419 - accuracy: 0.9839\n","Epoch 252/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0493 - accuracy: 0.9847\n","Epoch 253/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0498 - accuracy: 0.9837\n","Epoch 254/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0571 - accuracy: 0.9834\n","Epoch 255/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0607 - accuracy: 0.9824\n","Epoch 256/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0371 - accuracy: 0.9877\n","Epoch 257/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0421 - accuracy: 0.9852\n","Epoch 258/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0552 - accuracy: 0.9847\n","Epoch 259/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0615 - accuracy: 0.9865\n","Epoch 260/300\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0416 - accuracy: 0.9898\n","Epoch 261/300\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0413 - accuracy: 0.9908\n","Epoch 262/300\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0404 - accuracy: 0.9883\n","Epoch 263/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0468 - accuracy: 0.9870\n","Epoch 264/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0515 - accuracy: 0.9826\n","Epoch 265/300\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0574 - accuracy: 0.9839\n","Epoch 266/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0436 - accuracy: 0.9855\n","Epoch 267/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0434 - accuracy: 0.9872\n","Epoch 268/300\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0742 - accuracy: 0.9765\n","Epoch 269/300\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0792 - accuracy: 0.9770\n","Epoch 270/300\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0417 - accuracy: 0.9860\n","Epoch 271/300\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0369 - accuracy: 0.9883\n","Epoch 272/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0470 - accuracy: 0.9872\n","Epoch 273/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0611 - accuracy: 0.9832\n","Epoch 274/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0554 - accuracy: 0.9839\n","Epoch 275/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0489 - accuracy: 0.9852\n","Epoch 276/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0349 - accuracy: 0.9855\n","Epoch 277/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0332 - accuracy: 0.9883\n","Epoch 278/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0288 - accuracy: 0.9903\n","Epoch 279/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1063 - accuracy: 0.9765\n","Epoch 280/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1156 - accuracy: 0.9668\n","Epoch 281/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0509 - accuracy: 0.9814\n","Epoch 282/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0575 - accuracy: 0.9837\n","Epoch 283/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0491 - accuracy: 0.9849\n","Epoch 284/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0431 - accuracy: 0.9844\n","Epoch 285/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0258 - accuracy: 0.9911\n","Epoch 286/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0345 - accuracy: 0.9885\n","Epoch 287/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0617 - accuracy: 0.9844\n","Epoch 288/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0557 - accuracy: 0.9849\n","Epoch 289/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0528 - accuracy: 0.9883\n","Epoch 290/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0570 - accuracy: 0.9855\n","Epoch 291/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0568 - accuracy: 0.9839\n","Epoch 292/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0399 - accuracy: 0.9898\n","Epoch 293/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0358 - accuracy: 0.9890\n","Epoch 294/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0366 - accuracy: 0.9867\n","Epoch 295/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0451 - accuracy: 0.9895\n","Epoch 296/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0408 - accuracy: 0.9890\n","Epoch 297/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0655 - accuracy: 0.9829\n","Epoch 298/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0629 - accuracy: 0.9832\n","Epoch 299/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0399 - accuracy: 0.9883\n","Epoch 300/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1312 - accuracy: 0.9574\n","31/31 [==============================] - 0s 3ms/step - loss: 0.6914 - accuracy: 0.7949\n","Acuracia: 0.7948979735374451\n","loss 0.6913864612579346\n"]}]}]}