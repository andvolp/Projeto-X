{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1pI_DDTNmKsMfrHuxk-Ki53n9Eu1trVdw","timestamp":1690700941833},{"file_id":"14I8sIz1o_lt_54aYMgtinN584MZ1YMS5","timestamp":1690168233301},{"file_id":"12_BRZr-81GUBTOfoWh9UY5jxGuuRfU67","timestamp":1689647348513},{"file_id":"1gTnY5m8Oqcc22gvv7Q-Vu3Furn28v7o_","timestamp":1689462466876},{"file_id":"1eV8z9hqB1tLVW--hghWBjVoAaRf7HAEM","timestamp":1689399741826}],"gpuType":"T4","authorship_tag":"ABX9TyOcQYFKaGhTErbPkxQmEw7Z"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":22,"metadata":{"id":"_xfwnVnfrWdK","executionInfo":{"status":"ok","timestamp":1690704867904,"user_tz":180,"elapsed":225,"user":{"displayName":"André Felipe Shimizu Volpato","userId":"16593900034578429908"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import tensorflow\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, BatchNormalization\n","import tensorflow as tf\n","import io\n","from tensorflow.keras.utils import to_categorical\n","from google.colab import files"]},{"cell_type":"code","source":["\n","df = pd.read_csv('https://raw.githubusercontent.com/andvolp/Projeto-X/main/Projeto%201/winequality-white.csv', encoding='utf-8', sep=';')\n","\n","dfs = np.array(df)\n","\n","for i in range(len(dfs)):\n","  if dfs[i,11] > 5:\n","    dfs[i,11] = 1\n","  else:\n","    dfs[i,11] = 0\n","\n","# utilizarei o keras\n","\n","X = dfs[:,:-1]\n","y = dfs[:,11]\n","\n","scaler =StandardScaler()\n","X = scaler.fit_transform(X)\n","\n","X_train, X_test, y_train, y_test = train_test_split(X , y, test_size=0.2, random_state=3)\n","\n","\n","model = Sequential()\n","\n","model.add(tf.keras.Input(shape=(11,)))\n","\n","#Fully layer 1\n","model.add(tf.keras.layers.Flatten())\n","model.add(tf.keras.layers.Dense(1024))\n","#model.add(BatchNormalization())\n","model.add(tf.keras.layers.Activation('relu'))\n","model.add(tf.keras.layers.Dropout(0.1))\n","\n","#Fully layer 2\n","model.add(tf.keras.layers.Flatten())\n","model.add(tf.keras.layers.Dense(1024))\n","#model.add(BatchNormalization())\n","model.add(tf.keras.layers.Activation('relu'))\n","model.add(tf.keras.layers.Dropout(0.1))\n","\n","#Fully layer 3\n","model.add(tf.keras.layers.Flatten())\n","model.add(tf.keras.layers.Dense(1024))\n","#model.add(BatchNormalization())\n","model.add(tf.keras.layers.Activation('relu'))\n","model.add(tf.keras.layers.Dropout(0.1))\n","\n","#Fully layer 4\n","model.add(tf.keras.layers.Flatten())\n","model.add(tf.keras.layers.Dense(1024))\n","#model.add(BatchNormalization())\n","model.add(tf.keras.layers.Activation('relu'))\n","model.add(tf.keras.layers.Dropout(0.1))\n","\n","#Output\n","model.add(Dense(1))\n","model.add(tf.keras.layers.Activation('sigmoid'))\n","\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","historico = model.fit(X_train, y_train, epochs=300, batch_size=124, verbose=1)\n","\n","loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n","\n","log_stream = io.StringIO()\n","log_stream.write(f\"Loss: {loss}, Accuracy: {accuracy}\\n\")\n","log_stream.write(str(historico.history))\n","\n"," #Salvar o arquivo de log em disco\n","with open('historico.log', 'w') as f:\n","    f.write(log_stream.getvalue())\n","\n","#files.download('/content/history.log')\n","\n","print('Acuracia:', accuracy)\n","print('loss', loss)"],"metadata":{"id":"aiMSinsFsCeh","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8b8ffd7b-ad48-4cd5-f462-6d755a8bd32e","executionInfo":{"status":"ok","timestamp":1690705017800,"user_tz":180,"elapsed":149543,"user":{"displayName":"André Felipe Shimizu Volpato","userId":"16593900034578429908"}}},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/300\n","32/32 [==============================] - 100s 5ms/step - loss: 0.5373 - accuracy: 0.7432\n","Epoch 2/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7728\n","Epoch 3/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.4758 - accuracy: 0.7708\n","Epoch 4/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.4518 - accuracy: 0.7889\n","Epoch 5/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.4500 - accuracy: 0.7848\n","Epoch 6/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.7943\n","Epoch 7/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.4231 - accuracy: 0.8050\n","Epoch 8/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.4122 - accuracy: 0.8088\n","Epoch 9/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.3956 - accuracy: 0.8162\n","Epoch 10/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.3917 - accuracy: 0.8134\n","Epoch 11/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.3826 - accuracy: 0.8203\n","Epoch 12/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.3678 - accuracy: 0.8305\n","Epoch 13/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.3498 - accuracy: 0.8464\n","Epoch 14/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.3360 - accuracy: 0.8517\n","Epoch 15/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.3219 - accuracy: 0.8560\n","Epoch 16/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.3015 - accuracy: 0.8612\n","Epoch 17/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.2941 - accuracy: 0.8691\n","Epoch 18/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.2801 - accuracy: 0.8729\n","Epoch 19/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.2779 - accuracy: 0.8831\n","Epoch 20/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.2724 - accuracy: 0.8757\n","Epoch 21/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.2439 - accuracy: 0.8984\n","Epoch 22/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.2249 - accuracy: 0.8992\n","Epoch 23/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.2176 - accuracy: 0.9079\n","Epoch 24/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.2198 - accuracy: 0.9035\n","Epoch 25/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.1887 - accuracy: 0.9196\n","Epoch 26/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1928 - accuracy: 0.9191\n","Epoch 27/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.2024 - accuracy: 0.9130\n","Epoch 28/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.1794 - accuracy: 0.9245\n","Epoch 29/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.1812 - accuracy: 0.9186\n","Epoch 30/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.1719 - accuracy: 0.9278\n","Epoch 31/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.1557 - accuracy: 0.9316\n","Epoch 32/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.1365 - accuracy: 0.9438\n","Epoch 33/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1287 - accuracy: 0.9459\n","Epoch 34/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1301 - accuracy: 0.9487\n","Epoch 35/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.1191 - accuracy: 0.9482\n","Epoch 36/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.1149 - accuracy: 0.9513\n","Epoch 37/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1056 - accuracy: 0.9530\n","Epoch 38/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.1034 - accuracy: 0.9584\n","Epoch 39/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.1030 - accuracy: 0.9574\n","Epoch 40/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.1082 - accuracy: 0.9502\n","Epoch 41/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.1006 - accuracy: 0.9589\n","Epoch 42/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0857 - accuracy: 0.9622\n","Epoch 43/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.1027 - accuracy: 0.9632\n","Epoch 44/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0835 - accuracy: 0.9635\n","Epoch 45/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0902 - accuracy: 0.9617\n","Epoch 46/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0778 - accuracy: 0.9666\n","Epoch 47/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0738 - accuracy: 0.9681\n","Epoch 48/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0833 - accuracy: 0.9663\n","Epoch 49/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0917 - accuracy: 0.9594\n","Epoch 50/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0708 - accuracy: 0.9696\n","Epoch 51/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0712 - accuracy: 0.9722\n","Epoch 52/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0605 - accuracy: 0.9737\n","Epoch 53/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0498 - accuracy: 0.9798\n","Epoch 54/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0487 - accuracy: 0.9791\n","Epoch 55/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0733 - accuracy: 0.9684\n","Epoch 56/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0686 - accuracy: 0.9735\n","Epoch 57/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0666 - accuracy: 0.9758\n","Epoch 58/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0497 - accuracy: 0.9814\n","Epoch 59/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0545 - accuracy: 0.9778\n","Epoch 60/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0459 - accuracy: 0.9801\n","Epoch 61/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0640 - accuracy: 0.9732\n","Epoch 62/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0640 - accuracy: 0.9732\n","Epoch 63/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0590 - accuracy: 0.9755\n","Epoch 64/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0559 - accuracy: 0.9773\n","Epoch 65/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0568 - accuracy: 0.9791\n","Epoch 66/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0510 - accuracy: 0.9791\n","Epoch 67/300\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0461 - accuracy: 0.9811\n","Epoch 68/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0444 - accuracy: 0.9811\n","Epoch 69/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0541 - accuracy: 0.9809\n","Epoch 70/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0518 - accuracy: 0.9786\n","Epoch 71/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0432 - accuracy: 0.9842\n","Epoch 72/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0371 - accuracy: 0.9842\n","Epoch 73/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0437 - accuracy: 0.9811\n","Epoch 74/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0308 - accuracy: 0.9875\n","Epoch 75/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0398 - accuracy: 0.9839\n","Epoch 76/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0434 - accuracy: 0.9816\n","Epoch 77/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0378 - accuracy: 0.9855\n","Epoch 78/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0359 - accuracy: 0.9883\n","Epoch 79/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0452 - accuracy: 0.9837\n","Epoch 80/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0356 - accuracy: 0.9865\n","Epoch 81/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0446 - accuracy: 0.9837\n","Epoch 82/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0378 - accuracy: 0.9860\n","Epoch 83/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0347 - accuracy: 0.9865\n","Epoch 84/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0309 - accuracy: 0.9867\n","Epoch 85/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0359 - accuracy: 0.9842\n","Epoch 86/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0304 - accuracy: 0.9895\n","Epoch 87/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0384 - accuracy: 0.9855\n","Epoch 88/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0552 - accuracy: 0.9806\n","Epoch 89/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0356 - accuracy: 0.9860\n","Epoch 90/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0365 - accuracy: 0.9870\n","Epoch 91/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0303 - accuracy: 0.9877\n","Epoch 92/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0237 - accuracy: 0.9900\n","Epoch 93/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0415 - accuracy: 0.9847\n","Epoch 94/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0528 - accuracy: 0.9821\n","Epoch 95/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0362 - accuracy: 0.9857\n","Epoch 96/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0247 - accuracy: 0.9903\n","Epoch 97/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0368 - accuracy: 0.9872\n","Epoch 98/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0340 - accuracy: 0.9872\n","Epoch 99/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0389 - accuracy: 0.9855\n","Epoch 100/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0407 - accuracy: 0.9847\n","Epoch 101/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0313 - accuracy: 0.9867\n","Epoch 102/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0337 - accuracy: 0.9885\n","Epoch 103/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0260 - accuracy: 0.9900\n","Epoch 104/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0246 - accuracy: 0.9898\n","Epoch 105/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0404 - accuracy: 0.9862\n","Epoch 106/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0522 - accuracy: 0.9781\n","Epoch 107/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0313 - accuracy: 0.9875\n","Epoch 108/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0230 - accuracy: 0.9918\n","Epoch 109/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0494 - accuracy: 0.9834\n","Epoch 110/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0268 - accuracy: 0.9911\n","Epoch 111/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0199 - accuracy: 0.9916\n","Epoch 112/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0236 - accuracy: 0.9916\n","Epoch 113/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0264 - accuracy: 0.9908\n","Epoch 114/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0262 - accuracy: 0.9880\n","Epoch 115/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0266 - accuracy: 0.9898\n","Epoch 116/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0275 - accuracy: 0.9893\n","Epoch 117/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0240 - accuracy: 0.9898\n","Epoch 118/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0419 - accuracy: 0.9860\n","Epoch 119/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0273 - accuracy: 0.9895\n","Epoch 120/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0240 - accuracy: 0.9908\n","Epoch 121/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0284 - accuracy: 0.9906\n","Epoch 122/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0328 - accuracy: 0.9895\n","Epoch 123/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0282 - accuracy: 0.9900\n","Epoch 124/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0370 - accuracy: 0.9865\n","Epoch 125/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0322 - accuracy: 0.9857\n","Epoch 126/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0204 - accuracy: 0.9921\n","Epoch 127/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0365 - accuracy: 0.9872\n","Epoch 128/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0300 - accuracy: 0.9872\n","Epoch 129/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0277 - accuracy: 0.9893\n","Epoch 130/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0235 - accuracy: 0.9911\n","Epoch 131/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0321 - accuracy: 0.9903\n","Epoch 132/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0225 - accuracy: 0.9911\n","Epoch 133/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0236 - accuracy: 0.9898\n","Epoch 134/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0354 - accuracy: 0.9877\n","Epoch 135/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0277 - accuracy: 0.9885\n","Epoch 136/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0185 - accuracy: 0.9921\n","Epoch 137/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0206 - accuracy: 0.9921\n","Epoch 138/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0305 - accuracy: 0.9895\n","Epoch 139/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0433 - accuracy: 0.9842\n","Epoch 140/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0312 - accuracy: 0.9875\n","Epoch 141/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0308 - accuracy: 0.9893\n","Epoch 142/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0349 - accuracy: 0.9870\n","Epoch 143/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0334 - accuracy: 0.9862\n","Epoch 144/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0490 - accuracy: 0.9829\n","Epoch 145/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0258 - accuracy: 0.9911\n","Epoch 146/300\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0326 - accuracy: 0.9877\n","Epoch 147/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0274 - accuracy: 0.9888\n","Epoch 148/300\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0237 - accuracy: 0.9908\n","Epoch 149/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0281 - accuracy: 0.9929\n","Epoch 150/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0306 - accuracy: 0.9913\n","Epoch 151/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0270 - accuracy: 0.9908\n","Epoch 152/300\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0184 - accuracy: 0.9918\n","Epoch 153/300\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0275 - accuracy: 0.9900\n","Epoch 154/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0224 - accuracy: 0.9913\n","Epoch 155/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0247 - accuracy: 0.9918\n","Epoch 156/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0273 - accuracy: 0.9911\n","Epoch 157/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0174 - accuracy: 0.9929\n","Epoch 158/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0187 - accuracy: 0.9931\n","Epoch 159/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0340 - accuracy: 0.9880\n","Epoch 160/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0321 - accuracy: 0.9880\n","Epoch 161/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0280 - accuracy: 0.9893\n","Epoch 162/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0201 - accuracy: 0.9911\n","Epoch 163/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0301 - accuracy: 0.9890\n","Epoch 164/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0545 - accuracy: 0.9816\n","Epoch 165/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0308 - accuracy: 0.9875\n","Epoch 166/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0181 - accuracy: 0.9936\n","Epoch 167/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0200 - accuracy: 0.9918\n","Epoch 168/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0269 - accuracy: 0.9888\n","Epoch 169/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0272 - accuracy: 0.9888\n","Epoch 170/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0232 - accuracy: 0.9906\n","Epoch 171/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0174 - accuracy: 0.9929\n","Epoch 172/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0132 - accuracy: 0.9929\n","Epoch 173/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0215 - accuracy: 0.9931\n","Epoch 174/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0161 - accuracy: 0.9936\n","Epoch 175/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0214 - accuracy: 0.9913\n","Epoch 176/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0290 - accuracy: 0.9893\n","Epoch 177/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0345 - accuracy: 0.9875\n","Epoch 178/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0290 - accuracy: 0.9888\n","Epoch 179/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0303 - accuracy: 0.9911\n","Epoch 180/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0165 - accuracy: 0.9939\n","Epoch 181/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0183 - accuracy: 0.9936\n","Epoch 182/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0196 - accuracy: 0.9926\n","Epoch 183/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0238 - accuracy: 0.9898\n","Epoch 184/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0207 - accuracy: 0.9913\n","Epoch 185/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0255 - accuracy: 0.9913\n","Epoch 186/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0238 - accuracy: 0.9921\n","Epoch 187/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0234 - accuracy: 0.9918\n","Epoch 188/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0248 - accuracy: 0.9908\n","Epoch 189/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0197 - accuracy: 0.9934\n","Epoch 190/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0202 - accuracy: 0.9921\n","Epoch 191/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0265 - accuracy: 0.9913\n","Epoch 192/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0182 - accuracy: 0.9931\n","Epoch 193/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0166 - accuracy: 0.9941\n","Epoch 194/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0095 - accuracy: 0.9957\n","Epoch 195/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0104 - accuracy: 0.9952\n","Epoch 196/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0263 - accuracy: 0.9880\n","Epoch 197/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0203 - accuracy: 0.9906\n","Epoch 198/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0189 - accuracy: 0.9923\n","Epoch 199/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0255 - accuracy: 0.9926\n","Epoch 200/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0168 - accuracy: 0.9926\n","Epoch 201/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0251 - accuracy: 0.9906\n","Epoch 202/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0379 - accuracy: 0.9877\n","Epoch 203/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0263 - accuracy: 0.9895\n","Epoch 204/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0194 - accuracy: 0.9934\n","Epoch 205/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0168 - accuracy: 0.9941\n","Epoch 206/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0175 - accuracy: 0.9936\n","Epoch 207/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0221 - accuracy: 0.9913\n","Epoch 208/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0157 - accuracy: 0.9946\n","Epoch 209/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0168 - accuracy: 0.9921\n","Epoch 210/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0210 - accuracy: 0.9926\n","Epoch 211/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0169 - accuracy: 0.9939\n","Epoch 212/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0268 - accuracy: 0.9931\n","Epoch 213/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0212 - accuracy: 0.9908\n","Epoch 214/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0319 - accuracy: 0.9906\n","Epoch 215/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0250 - accuracy: 0.9900\n","Epoch 216/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0196 - accuracy: 0.9913\n","Epoch 217/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0324 - accuracy: 0.9898\n","Epoch 218/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0312 - accuracy: 0.9877\n","Epoch 219/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0168 - accuracy: 0.9939\n","Epoch 220/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0245 - accuracy: 0.9921\n","Epoch 221/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0223 - accuracy: 0.9923\n","Epoch 222/300\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0122 - accuracy: 0.9944\n","Epoch 223/300\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0102 - accuracy: 0.9954\n","Epoch 224/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0129 - accuracy: 0.9954\n","Epoch 225/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0180 - accuracy: 0.9926\n","Epoch 226/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0205 - accuracy: 0.9926\n","Epoch 227/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0162 - accuracy: 0.9926\n","Epoch 228/300\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0146 - accuracy: 0.9952\n","Epoch 229/300\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0217 - accuracy: 0.9923\n","Epoch 230/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0202 - accuracy: 0.9918\n","Epoch 231/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0156 - accuracy: 0.9929\n","Epoch 232/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0221 - accuracy: 0.9934\n","Epoch 233/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0257 - accuracy: 0.9906\n","Epoch 234/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0256 - accuracy: 0.9916\n","Epoch 235/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0231 - accuracy: 0.9934\n","Epoch 236/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0116 - accuracy: 0.9957\n","Epoch 237/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.9954\n","Epoch 238/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0087 - accuracy: 0.9962\n","Epoch 239/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0061 - accuracy: 0.9974\n","Epoch 240/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0098 - accuracy: 0.9944\n","Epoch 241/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0193 - accuracy: 0.9939\n","Epoch 242/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0314 - accuracy: 0.9918\n","Epoch 243/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0277 - accuracy: 0.9916\n","Epoch 244/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0222 - accuracy: 0.9916\n","Epoch 245/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0319 - accuracy: 0.9923\n","Epoch 246/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0299 - accuracy: 0.9872\n","Epoch 247/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0238 - accuracy: 0.9929\n","Epoch 248/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0303 - accuracy: 0.9883\n","Epoch 249/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0250 - accuracy: 0.9900\n","Epoch 250/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0188 - accuracy: 0.9934\n","Epoch 251/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0189 - accuracy: 0.9918\n","Epoch 252/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0186 - accuracy: 0.9934\n","Epoch 253/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0264 - accuracy: 0.9913\n","Epoch 254/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0329 - accuracy: 0.9903\n","Epoch 255/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0154 - accuracy: 0.9934\n","Epoch 256/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0261 - accuracy: 0.9883\n","Epoch 257/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0251 - accuracy: 0.9916\n","Epoch 258/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0120 - accuracy: 0.9954\n","Epoch 259/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0210 - accuracy: 0.9944\n","Epoch 260/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0164 - accuracy: 0.9936\n","Epoch 261/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0156 - accuracy: 0.9923\n","Epoch 262/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0140 - accuracy: 0.9929\n","Epoch 263/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0120 - accuracy: 0.9954\n","Epoch 264/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0150 - accuracy: 0.9941\n","Epoch 265/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0099 - accuracy: 0.9957\n","Epoch 266/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0175 - accuracy: 0.9946\n","Epoch 267/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0187 - accuracy: 0.9931\n","Epoch 268/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0174 - accuracy: 0.9939\n","Epoch 269/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0186 - accuracy: 0.9931\n","Epoch 270/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0103 - accuracy: 0.9959\n","Epoch 271/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0358 - accuracy: 0.9893\n","Epoch 272/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0315 - accuracy: 0.9883\n","Epoch 273/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0243 - accuracy: 0.9911\n","Epoch 274/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0191 - accuracy: 0.9934\n","Epoch 275/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0217 - accuracy: 0.9916\n","Epoch 276/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0203 - accuracy: 0.9936\n","Epoch 277/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0232 - accuracy: 0.9913\n","Epoch 278/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0185 - accuracy: 0.9931\n","Epoch 279/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0173 - accuracy: 0.9946\n","Epoch 280/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0191 - accuracy: 0.9939\n","Epoch 281/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0127 - accuracy: 0.9946\n","Epoch 282/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0163 - accuracy: 0.9941\n","Epoch 283/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0169 - accuracy: 0.9929\n","Epoch 284/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0168 - accuracy: 0.9946\n","Epoch 285/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0181 - accuracy: 0.9941\n","Epoch 286/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0133 - accuracy: 0.9939\n","Epoch 287/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0121 - accuracy: 0.9939\n","Epoch 288/300\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0105 - accuracy: 0.9952\n","Epoch 289/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0149 - accuracy: 0.9944\n","Epoch 290/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0180 - accuracy: 0.9929\n","Epoch 291/300\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0208 - accuracy: 0.9918\n","Epoch 292/300\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0300 - accuracy: 0.9880\n","Epoch 293/300\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0142 - accuracy: 0.9949\n","Epoch 294/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0125 - accuracy: 0.9939\n","Epoch 295/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0172 - accuracy: 0.9923\n","Epoch 296/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0189 - accuracy: 0.9931\n","Epoch 297/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0135 - accuracy: 0.9936\n","Epoch 298/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0174 - accuracy: 0.9936\n","Epoch 299/300\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0265 - accuracy: 0.9908\n","Epoch 300/300\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0197 - accuracy: 0.9929\n","31/31 [==============================] - 0s 4ms/step - loss: 1.5268 - accuracy: 0.8122\n","Acuracia: 0.8122448921203613\n","loss 1.5267571210861206\n"]}]}]}